# Description: This script processes raw counts matrix generated from step_3_wig_to_txt.sh and generate CPM (counts-per-million), logCPM (lcpm) and TMM-normalized counts. Library batch effects was also reduced using sva/ComBat-seq.
## Author：Kui Chen → kui.chen@uhn.ca
## Date Created: 2020-08-21
## Last Modified: 2022-03-11

#####################################################################################################
# Before starting, do the followings ################################################################
# 1.make working directory "/path/to/your/matrices" #################################################
# 2.copy support files "hg19_chr1_22_m_coord.rds" to the working directory ########
#####################################################################################################

library(dplyr)
library(data.table)
library(edgeR)
library(limma)
library(reshape2)
library(tidyr)
library(sva)

# Define the working directory and output directory
dir <- "/path/to/your/matrices"  #path to the txt files generated by wig_to_txt.sh

# Ensure the output directory exists, otherwise create it
if (!dir.exists(outdir)) {
  dir.create(outdir, recursive = TRUE)
}

# Loading genomic coordinates for hg19 (chr:1-22 and M)
coo <- readRDS("hg19_chr1_22_m_coord.rds")

# load # Loading and preparing count data from wig-txt files
AllSamplesCounts <- list.files(pattern = "*.txt$")
WigNames <- AllSamplesCounts
AllSamplesCounts <- lapply(AllSamplesCounts, function(x) fread(x, header = F, data.table = F ))
AllSamplesCounts <- do.call(cbind,AllSamplesCounts)
names(AllSamplesCounts) <- WigNames
rm(WigNames)

# confirm coo and counts rows
identical(nrow(coo), nrow(AllSamplesCounts))

#Attaching genomic coordinates to count data and ensuring consistency
AllSamplesCounts_withCoords <- cbind(coo, AllSamplesCounts)
rownames(AllSamplesCounts_withCoords) <- AllSamplesCounts_withCoords$WindowsCoords
identical(rownames(AllSamplesCounts_withCoords), AllSamplesCounts_withCoords$WindowsCoords)

AllSamplesCounts_withCoords <- AllSamplesCounts_withCoords[,-c(1:4)]

# simplify colnames
colnames(AllSamplesCounts_withCoords) <- gsub(".txt", "", colnames(AllSamplesCounts_withCoords))
sample <- as.data.frame(colnames(AllSamplesCounts_withCoords), drop=F)
colnames(sample) <- c("RUN_ID")

count <- as.data.frame(AllSamplesCounts_withCoords)

# Check if the number of rows in the coo matrix is equal to the number of rows in the Counts_n236_chr1_22_M matrix
if(nrow(coo) == nrow(count)) {
  print("The row numbers of coo and count matrices are consistent.")
} else {
  print("Warning: The row numbers of coo and count matrices are not consistent.")
}

# Assign Sample ID (replace RUN_ID with Sample_ID)
samples <- readRDS('sample.rds')

# Ensure the column names of count_236 match sample$RUN_ID
if (!all(colnames(count) %in% sample$RUN_ID)) {
 stop("Some column names in count_236 do not match RUN_ID in sample.")
}
# Create a mapping vector from RUN_ID to Sample_ID
name_mapping <- setNames(sample$Sample_ID, sample$RUN_ID)
# Replace the column names of count with corresponding Sample_IDs
colnames(count) <- name_mapping[colnames(count)]
# Check the result
print(head(count))
identical(colnames(count), sample$Sample_ID)

# Save the processed matrices
save(count, samples, file="Counts_n236.RData")

# load("Counts_n236_chr1_22_M.RData")

# Organizing samples and filtering low-count bins
identical(samples$Sample_ID, colnames(count))
counts <- count[rowSums(count) >= 1, ]

# set group info
# table(samples$Group)
group <- as.factor(samples$Group_1)

# check group & batch
table(samples$Batch)

# batch effect reducing
batch <- as.factor(samples$Batch)
adj <- ComBat_seq(counts, batch=batch, group=group)
class(adj)
#saveRDS(adj,file="Counts_n236_BE_rd.rds")

# load batch-effecte-reduced counts
counts <- readRDS("Counts_n236_BE_rd.rds")
counts <- as.data.frame(counts)

# set group info
group <- as.factor(samples$Group_1)
design <- model.matrix(~group)

# build DGEList
DGEList <- DGEList(counts = counts, group = group)

# filter out low expressed data
# check all-0 counts
class(DGEList)
table(rowSums(DGEList$counts==0)==236)

# option-1 : remove low expressed data using 20% low counts cutoff threshold
keep <- rowSums(DGEList$counts > 0) >= floor(0.8*ncol(DGEList$counts))
x <- DGEList[keep,,keep.lib.sizes = FALSE]
dim(x)
class(x)

# Options for removing using low counts
## Option-2
#keep <- rowSums(edgeR::cpm(mycounts[-1])>0) >= 2

## Option-3
#keep <- rowSums(cpm(y)>1) >= 2

## Option-4
#keep <- filterByExpr(y,group=Group)

# TMM normalization
dge <- calcNormFactors(x, method = "TMM")
dim(dge)
range(dge)

# Generating count per million (CPM) and log-CPM matrices
cpm <- cpm(dge)
lcpm <- cpm(dge, log=TRUE, prior.count=2)
lcpmx <- log(cpm+1)

# generating voom normalizated counts
v <- voom(dge, design, plot=TRUE)
vCounts <- v$E
sample <- v$targets
design <- v$design

# saving data
saveRDS(cpm, file="n236_cpm.rds")
saveRDS(lcpm, file="n236_lcpm.rds")
saveRDS(vCounts, file="vCount_n236.rds")




